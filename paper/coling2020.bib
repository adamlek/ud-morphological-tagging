@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}

@article{mccarthy2018marrying,
  title={Marrying universal dependencies and universal morphology},
  author={McCarthy, Arya D and Silfverberg, Miikka and Cotterell, Ryan and Hulden, Mans and Yarowsky, David},
  journal={arXiv preprint arXiv:1810.06743},
  year={2018}
  }
  
@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}
  
 @article{nivre2018,
 title = {Universal Dependencies 2.2},
 author = {Nivre, Joakim and others},
 url = {http://hdl.handle.net/11234/1-2837},
 note = {{LINDAT}/{CLARIAH}-{CZ} digital library at the Institute of Formal and Applied Linguistics ({{\'U}FAL}), Faculty of Mathematics and Physics, Charles University},
 copyright = {Licence Universal Dependencies v2.2},
 year = {2018} }
 
 @article{mccarthy2019sigmorphon,
  title={The SIGMORPHON 2019 shared task: Morphological analysis in context and cross-lingual transfer for inflection},
  author={McCarthy, Arya D and Vylomova, Ekaterina and Wu, Shijie and Malaviya, Chaitanya and Wolf-Sonkin, Lawrence and Nicolai, Garrett and Kirov, Christo and Silfverberg, Miikka and Mielke, Sebastian J and Heinz, Jeffrey and others},
  journal={arXiv preprint arXiv:1910.11493},
  year={2019}
}

@article{conneau2019unsupervised,
  title={Unsupervised cross-lingual representation learning at scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1911.02116},
  year={2019}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}